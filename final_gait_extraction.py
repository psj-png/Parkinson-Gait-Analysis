import os
import sys
import cv2
import pandas as pd
from tqdm import tqdm

# [ë³´ì•ˆì±…] ê²½ë¡œ ê¼¬ì„ ë°©ì§€
if os.getcwd() in sys.path:
    sys.path.remove(os.getcwd())

# 1. MediaPipe ë¡œë“œ
try:
    import mediapipe as mp

    try:
        mp_pose = mp.solutions.pose
    except AttributeError:
        from mediapipe.python.solutions import pose as mp_pose

    pose = mp_pose.Pose(
        static_image_mode=False,
        min_detection_confidence=0.5,
        model_complexity=1
    )
    print("âœ… [ì„±ê³µ] MediaPipe ê´€ì ˆ ëª¨ë¸ì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.")

except Exception as e:
    print(f"âŒ [ì¹˜ëª…ì  ì˜¤ë¥˜] ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì‹¤íŒ¨: {e}")
    sys.exit()

# 2. ê²½ë¡œ ì„¤ì •
BASE_PATH = r'C:\Gait_Analysis'
DATA_DIR = os.path.join(BASE_PATH, 'data')
OUTPUT_DIR = os.path.join(BASE_PATH, 'extracted_data')

if not os.path.exists(OUTPUT_DIR):
    os.makedirs(OUTPUT_DIR)


def run_extraction():
    all_rows = []

    # [ìˆ˜ì •] data í´ë” ë‚´ì˜ ëª¨ë“  í•˜ìœ„ í´ë”ë¥¼ ìë™ìœ¼ë¡œ íƒìƒ‰í•©ë‹ˆë‹¤.
    target_categories = [d for d in os.listdir(DATA_DIR) if os.path.isdir(os.path.join(DATA_DIR, d))]

    print(f"ğŸ“‚ ë¶„ì„ ëŒ€ìƒ í´ë” ë°œê²¬: {target_categories}")

    for category in target_categories:
        cat_path = os.path.join(DATA_DIR, category)
        # ì§€ì›í•˜ëŠ” ëª¨ë“  ì˜ìƒ ë° GIF í™•ì¥ì í¬í•¨
        videos = [f for f in os.listdir(cat_path) if f.lower().endswith(('.mp4', '.avi', '.gif', '.mov'))]

        if not videos:
            continue

        print(f"\nğŸ¬ [{category}] ì‘ì—… ì‹œì‘ (ì´ {len(videos)}ê°œ íŒŒì¼)")

        for v_name in tqdm(videos):
            v_path = os.path.join(cat_path, v_name)
            cap = cv2.VideoCapture(v_path)
            f_idx = 0

            while cap.isOpened():
                ret, frame = cap.read()
                if not ret: break

                # ì´ë¯¸ì§€ ì²˜ë¦¬
                rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                res = pose.process(rgb)

                if res.pose_landmarks:
                    # ê¸°ë³¸ ì •ë³´ (ì˜ìƒëª…, ë¼ë²¨, í”„ë ˆì„ ë²ˆí˜¸)
                    data = {'video': v_name, 'label': category, 'frame': f_idx}

                    # 33ê°œ ê´€ì ˆì˜ x, y, z, ì‹ ë¢°ë„(v) ì¶”ì¶œ
                    for i, lm in enumerate(res.pose_landmarks.landmark):
                        data[f'j{i}_x'] = lm.x
                        data[f'j{i}_y'] = lm.y
                        data[f'j{i}_z'] = lm.z
                        data[f'j{i}_v'] = lm.visibility  # AI ì¸ì‹ ì‹ ë¢°ë„ í¬í•¨

                    all_rows.append(data)
                f_idx += 1
            cap.release()

    # 3. ê²°ê³¼ í†µí•© ì €ì¥
    if all_rows:
        df = pd.DataFrame(all_rows)
        save_file = os.path.join(OUTPUT_DIR, 'gait_integrated_data.csv')
        df.to_csv(save_file, index=False, encoding='utf-8-sig')
        print(f"\nâœ¨ ì „ìˆ˜ ì¶”ì¶œ ì™„ë£Œ! íŒŒì¼ ê²½ë¡œ: {save_file}")
        print(f"ğŸ“Š ìµœì¢… ë°ì´í„° í–‰ ìˆ˜: {len(df)}")
    else:
        print("\nâŒ ë¶„ì„í•  ì˜ìƒ íŒŒì¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. data í´ë” êµ¬ì„±ì„ í™•ì¸í•´ ì£¼ì„¸ìš”.")


if __name__ == "__main__":
    run_extraction()